{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recognize named entities on Twitter with LSTMs\n",
    "\n",
    "In this assignment, you will use a recurrent neural network to solve Named Entity Recognition (NER) problem. NER is a common task in natural language processing systems. It serves for extraction such entities from the text as persons, organizations, locations, etc. In this task you will experiment to recognize named entities from Twitter.\n",
    "\n",
    "For example, we want to extract persons' and organizations' names from the text. Than for the input text:\n",
    "\n",
    "    Ian Goodfellow works for Google Brain\n",
    "\n",
    "a NER model needs to provide the following sequence of tags:\n",
    "\n",
    "    B-PER I-PER    O     O   B-ORG  I-ORG\n",
    "\n",
    "Where *B-* and *I-* prefixes stand for the beginning and inside of the entity, while *O* stands for out of tag or no tag. Markup with the prefix scheme is called *BIO markup*. This markup is introduced for distinguishing of consequent entities with similar types.\n",
    "\n",
    "A solution of the task will be based on neural networks, particularly, on Bi-Directional Long Short-Term Memory Networks (Bi-LSTMs).\n",
    "\n",
    "### Libraries\n",
    "\n",
    "For this task you will need the following libraries:\n",
    " - [Tensorflow](https://www.tensorflow.org) — an open-source software library for Machine Intelligence.\n",
    " \n",
    "In this assignment, we use Tensorflow 1.15.0. You can install it with pip:\n",
    "\n",
    "    !pip install tensorflow==1.15.0\n",
    "     \n",
    " - [Numpy](http://www.numpy.org) — a package for scientific computing.\n",
    " \n",
    "If you have never worked with Tensorflow, you would probably need to read some tutorials during your work on this assignment, e.g. [this one](https://www.tensorflow.org/tutorials/recurrent) could be a good starting point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The following cell will download all data required for this assignment into the folder `week2/data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/train.txt is already downloaded.\n",
      "File data/validation.txt is already downloaded.\n",
      "File data/test.txt is already downloaded.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    ! wget https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py -O setup_google_colab.py\n",
    "    import setup_google_colab\n",
    "    setup_google_colab.setup_week2()\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common.download_utils import download_week2_resources\n",
    "\n",
    "download_week2_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Twitter Named Entity Recognition corpus\n",
    "\n",
    "We will work with a corpus, which contains tweets with NE tags. Every line of a file contains a pair of a token (word/punctuation symbol) and a tag, separated by a whitespace. Different tweets are separated by an empty line.\n",
    "\n",
    "The function *read_data* reads a corpus from the *file_path* and returns two lists: one with tokens and one with the corresponding tags. You need to complete this function by adding a code, which will replace a user's nickname to `<USR>` token and any URL to `<URL>` token. You could think that a URL and a nickname are just strings which start with *http://* or *https://* in case of URLs and a *@* symbol for nicknames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    \n",
    "    tweet_tokens = []\n",
    "    tweet_tags = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            if tweet_tokens:\n",
    "                tokens.append(tweet_tokens)\n",
    "                tags.append(tweet_tags)\n",
    "            tweet_tokens = []\n",
    "            tweet_tags = []\n",
    "        else:\n",
    "            token, tag = line.split()\n",
    "            # Replace all urls with <URL> token\n",
    "            # Replace all users with <USR> token\n",
    "            if token.startswith(\"http\"):\n",
    "                token = \"<URL>\"\n",
    "            elif token.startswith(\"@\"):\n",
    "                token = \"<USR>\"\n",
    "\n",
    "            ######################################\n",
    "            ######### YOUR CODE HERE #############\n",
    "            ######################################\n",
    "            \n",
    "            tweet_tokens.append(token)\n",
    "            tweet_tags.append(tag)\n",
    "            \n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can load three separate parts of the dataset:\n",
    " - *train* data for training the model;\n",
    " - *validation* data for evaluation and hyperparameters tuning;\n",
    " - *test* data for final evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_tags = read_data('data/train.txt')\n",
    "validation_tokens, validation_tags = read_data('data/validation.txt')\n",
    "test_tokens, test_tags = read_data('data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should always understand what kind of data you deal with. For this purpose, you can print the data running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT\tO\n",
      "<USR>\tO\n",
      ":\tO\n",
      "Online\tO\n",
      "ticket\tO\n",
      "sales\tO\n",
      "for\tO\n",
      "Ghostland\tB-musicartist\n",
      "Observatory\tI-musicartist\n",
      "extended\tO\n",
      "until\tO\n",
      "6\tO\n",
      "PM\tO\n",
      "EST\tO\n",
      "due\tO\n",
      "to\tO\n",
      "high\tO\n",
      "demand\tO\n",
      ".\tO\n",
      "Get\tO\n",
      "them\tO\n",
      "before\tO\n",
      "they\tO\n",
      "sell\tO\n",
      "out\tO\n",
      "...\tO\n",
      "\n",
      "Apple\tB-product\n",
      "MacBook\tI-product\n",
      "Pro\tI-product\n",
      "A1278\tI-product\n",
      "13.3\tI-product\n",
      "\"\tI-product\n",
      "Laptop\tI-product\n",
      "-\tI-product\n",
      "MD101LL/A\tI-product\n",
      "(\tO\n",
      "June\tO\n",
      ",\tO\n",
      "2012\tO\n",
      ")\tO\n",
      "-\tO\n",
      "Full\tO\n",
      "read\tO\n",
      "by\tO\n",
      "eBay\tB-company\n",
      "<URL>\tO\n",
      "<URL>\tO\n",
      "\n",
      "Happy\tO\n",
      "Birthday\tO\n",
      "<USR>\tO\n",
      "!\tO\n",
      "May\tO\n",
      "Allah\tB-person\n",
      "s.w.t\tO\n",
      "bless\tO\n",
      "you\tO\n",
      "with\tO\n",
      "goodness\tO\n",
      "and\tO\n",
      "happiness\tO\n",
      ".\tO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    for token, tag in zip(train_tokens[i], train_tags[i]):\n",
    "        print('%s\\t%s' % (token, tag))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dictionaries\n",
    "\n",
    "To train a neural network, we will use two mappings: \n",
    "- {token}$\\to${token id}: address the row in embeddings matrix for the current token;\n",
    "- {tag}$\\to${tag id}: one-hot ground truth probability distribution vectors for computing the loss at the output of the network.\n",
    "\n",
    "Now you need to implement the function *build_dict* which will return {token or tag}$\\to${index} and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(tokens_or_tags, special_tokens):\n",
    "    \"\"\"\n",
    "        tokens_or_tags: a list of lists of tokens or tags\n",
    "        special_tokens: some special tokens\n",
    "    \"\"\"\n",
    "    # Create a dictionary with default value 0\n",
    "    tok2idx = defaultdict(lambda: 0)\n",
    "    idx2tok = []\n",
    "    \n",
    "    # Create mappings from tokens (or tags) to indices and vice versa.\n",
    "    # At first, add special tokens (or tags) to the dictionaries.\n",
    "    # The first special token must have index 0.\n",
    "    \n",
    "    # Mapping tok2idx should contain each token or tag only once. \n",
    "    # To do so, you should:\n",
    "    # 1. extract unique tokens/tags from the tokens_or_tags variable, which is not\n",
    "    #    occur in special_tokens (because they could have non-empty intersection)\n",
    "    # 2. index them (for example, you can add them into the list idx2tok\n",
    "    # 3. for each token/tag save the index into tok2idx).\n",
    "    \n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    merged_tokens_or_tags = set()\n",
    "    for tokens in tokens_or_tags:\n",
    "        merged_tokens_or_tags = merged_tokens_or_tags.union(tokens)\n",
    "\n",
    "    special_tokens = list(set(special_tokens))\n",
    "    idx2tok.extend(special_tokens)\n",
    "    for token in merged_tokens_or_tags:\n",
    "        if token not in special_tokens:\n",
    "            idx2tok.append(token)\n",
    "            \n",
    "    for i in range(len(idx2tok)):\n",
    "        tok2idx[idx2tok[i]] = i\n",
    "    \n",
    "    return tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing the function *build_dict* you can make dictionaries for tokens and tags. Special tokens in our case will be:\n",
    " - `<UNK>` token for out of vocabulary tokens;\n",
    " - `<PAD>` token for padding sentence to the same length when we create batches of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<UNK>', '<PAD>']\n",
    "special_tags = ['O']\n",
    "\n",
    "# Create dictionaries \n",
    "token2idx, idx2token = build_dict(train_tokens + validation_tokens, special_tokens)\n",
    "tag2idx, idx2tag = build_dict(train_tags, special_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next additional functions will help you to create the mapping between tokens and ids for a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2idxs(tokens_list):\n",
    "    return [token2idx[word] for word in tokens_list]\n",
    "\n",
    "def tags2idxs(tags_list):\n",
    "    return [tag2idx[tag] for tag in tags_list]\n",
    "\n",
    "def idxs2words(idxs):\n",
    "    return [idx2token[idx] for idx in idxs]\n",
    "\n",
    "def idxs2tags(idxs):\n",
    "    return [idx2tag[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_of_words = len(idx2token)\n",
    "num_of_tags = len(idx2tag)\n",
    "\n",
    "max_length = 0\n",
    "for sentence in train_tokens + validation_tokens + test_tokens:\n",
    "    if len(sentence) > max_length:\n",
    "        max_length = len(sentence)\n",
    "\n",
    "X_train = [words2idxs(sentence) for sentence in train_tokens]\n",
    "X_train = pad_sequences(maxlen=max_length, sequences=X_train, padding=\"post\", value=token2idx[\"PAD\"])\n",
    "\n",
    "y_train = [tags2idxs(tags) for tags in train_tags]\n",
    "y_train = pad_sequences(maxlen=max_length, sequences=y_train, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y_train = [to_categorical(i, num_classes=num_of_tags) for i in y_train]\n",
    "\n",
    "X_val = [words2idxs(sentence) for sentence in validation_tokens]\n",
    "X_val = pad_sequences(maxlen=max_length, sequences=X_val, padding=\"post\", value=token2idx[\"PAD\"])\n",
    "\n",
    "y_val = [tags2idxs(tags) for tags in validation_tags]\n",
    "y_val = pad_sequences(maxlen=max_length, sequences=y_val, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y_val = [to_categorical(i, num_classes=num_of_tags) for i in y_val]\n",
    "\n",
    "X_test = [words2idxs(sentence) for sentence in test_tokens]\n",
    "X_test = pad_sequences(maxlen=max_length, sequences=X_test, padding=\"post\", value=token2idx[\"PAD\"])\n",
    "\n",
    "y_test = [tags2idxs(tags) for tags in test_tags]\n",
    "y_test = pad_sequences(maxlen=max_length, sequences=y_test, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y_test = [to_categorical(i, num_classes=num_of_tags) for i in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a recurrent neural network\n",
    "\n",
    "This is the most important part of the assignment. Here we will specify the network architecture based on TensorFlow building blocks. It's fun and easy as a lego constructor! We will create an LSTM network which will produce probability distribution over tags for each token in a sentence. To take into account both right and left contexts of the token, we will use Bi-Directional LSTM (Bi-LSTM). Dense layer will be used on top to perform tag classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import TimeDistributed, Dropout, Bidirectional\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 41)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 41, 300)           6151200   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 41, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 41, 128)           186880    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 41, 21)            2709      \n",
      "=================================================================\n",
      "Total params: 6,340,789\n",
      "Trainable params: 6,340,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 15:20:22.663087: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-17 15:20:22.663219: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((max_length,))\n",
    "x = Embedding(input_dim=num_of_words, output_dim=300, input_length=max_length)(inputs)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, activation=\"tanh\"))(x)\n",
    "outputs = TimeDistributed(Dense(num_of_tags, activation=\"softmax\"))(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 15:20:22.980225: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-02-17 15:20:22.980390: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 15:20:23.633156: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 15:20:23.749831: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 15:20:23.769556: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 15:20:23.919495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 15:20:23.936002: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.9489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 15:20:28.571868: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 15:20:28.612549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 15:20:28.618958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 6s 54ms/step - loss: 0.5999 - accuracy: 0.9489 - val_loss: 0.1890 - val_accuracy: 0.9700\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1991 - accuracy: 0.9679 - val_loss: 0.1866 - val_accuracy: 0.9700\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.1971 - accuracy: 0.9679 - val_loss: 0.1848 - val_accuracy: 0.9700\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.1942 - accuracy: 0.9679 - val_loss: 0.1820 - val_accuracy: 0.9700\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.1908 - accuracy: 0.9679 - val_loss: 0.1788 - val_accuracy: 0.9700\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.1855 - accuracy: 0.9679 - val_loss: 0.1739 - val_accuracy: 0.9700\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.1799 - accuracy: 0.9679 - val_loss: 0.1688 - val_accuracy: 0.9700\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.1721 - accuracy: 0.9679 - val_loss: 0.1610 - val_accuracy: 0.9700\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1624 - accuracy: 0.9680 - val_loss: 0.1532 - val_accuracy: 0.9702\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1526 - accuracy: 0.9683 - val_loss: 0.1471 - val_accuracy: 0.9703\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1444 - accuracy: 0.9689 - val_loss: 0.1411 - val_accuracy: 0.9707\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1365 - accuracy: 0.9696 - val_loss: 0.1362 - val_accuracy: 0.9714\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1308 - accuracy: 0.9703 - val_loss: 0.1329 - val_accuracy: 0.9715\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.1258 - accuracy: 0.9709 - val_loss: 0.1301 - val_accuracy: 0.9718\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.1200 - accuracy: 0.9715 - val_loss: 0.1317 - val_accuracy: 0.9725\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.1159 - accuracy: 0.9723 - val_loss: 0.1274 - val_accuracy: 0.9728\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1108 - accuracy: 0.9730 - val_loss: 0.1262 - val_accuracy: 0.9730\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1071 - accuracy: 0.9737 - val_loss: 0.1239 - val_accuracy: 0.9729\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.1023 - accuracy: 0.9746 - val_loss: 0.1267 - val_accuracy: 0.9732\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0988 - accuracy: 0.9753 - val_loss: 0.1232 - val_accuracy: 0.9737\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0962 - accuracy: 0.9756 - val_loss: 0.1232 - val_accuracy: 0.9737\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0929 - accuracy: 0.9761 - val_loss: 0.1234 - val_accuracy: 0.9736\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0906 - accuracy: 0.9767 - val_loss: 0.1279 - val_accuracy: 0.9741\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0874 - accuracy: 0.9774 - val_loss: 0.1258 - val_accuracy: 0.9740\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0849 - accuracy: 0.9779 - val_loss: 0.1252 - val_accuracy: 0.9737\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0827 - accuracy: 0.9783 - val_loss: 0.1228 - val_accuracy: 0.9744\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0802 - accuracy: 0.9791 - val_loss: 0.1241 - val_accuracy: 0.9740\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0785 - accuracy: 0.9792 - val_loss: 0.1242 - val_accuracy: 0.9743\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0744 - accuracy: 0.9801 - val_loss: 0.1263 - val_accuracy: 0.9746\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0730 - accuracy: 0.9806 - val_loss: 0.1249 - val_accuracy: 0.9744\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0707 - accuracy: 0.9810 - val_loss: 0.1238 - val_accuracy: 0.9745\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0687 - accuracy: 0.9811 - val_loss: 0.1252 - val_accuracy: 0.9739\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0678 - accuracy: 0.9814 - val_loss: 0.1257 - val_accuracy: 0.9751\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0651 - accuracy: 0.9821 - val_loss: 0.1302 - val_accuracy: 0.9755\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0628 - accuracy: 0.9828 - val_loss: 0.1296 - val_accuracy: 0.9753\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0615 - accuracy: 0.9829 - val_loss: 0.1318 - val_accuracy: 0.9749\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0594 - accuracy: 0.9834 - val_loss: 0.1365 - val_accuracy: 0.9754\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0580 - accuracy: 0.9839 - val_loss: 0.1301 - val_accuracy: 0.9752\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0566 - accuracy: 0.9840 - val_loss: 0.1350 - val_accuracy: 0.9752\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0555 - accuracy: 0.9840 - val_loss: 0.1354 - val_accuracy: 0.9755\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0526 - accuracy: 0.9851 - val_loss: 0.1392 - val_accuracy: 0.9756\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0514 - accuracy: 0.9850 - val_loss: 0.1395 - val_accuracy: 0.9754\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0502 - accuracy: 0.9856 - val_loss: 0.1414 - val_accuracy: 0.9751\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0501 - accuracy: 0.9857 - val_loss: 0.1417 - val_accuracy: 0.9756\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0478 - accuracy: 0.9862 - val_loss: 0.1401 - val_accuracy: 0.9755\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0461 - accuracy: 0.9866 - val_loss: 0.1418 - val_accuracy: 0.9755\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0447 - accuracy: 0.9871 - val_loss: 0.1424 - val_accuracy: 0.9753\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.1458 - val_accuracy: 0.9759\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0423 - accuracy: 0.9877 - val_loss: 0.1424 - val_accuracy: 0.9744\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0408 - accuracy: 0.9881 - val_loss: 0.1454 - val_accuracy: 0.9759\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0394 - accuracy: 0.9883 - val_loss: 0.1444 - val_accuracy: 0.9759\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 4s 49ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.1428 - val_accuracy: 0.9759\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.1483 - val_accuracy: 0.9764\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.1487 - val_accuracy: 0.9763\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 0.1482 - val_accuracy: 0.9759\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0344 - accuracy: 0.9899 - val_loss: 0.1475 - val_accuracy: 0.9760\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0331 - accuracy: 0.9901 - val_loss: 0.1573 - val_accuracy: 0.9760\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.1508 - val_accuracy: 0.9758\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.1567 - val_accuracy: 0.9764\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.1582 - val_accuracy: 0.9761\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.1599 - val_accuracy: 0.9758\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.1607 - val_accuracy: 0.9762\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.1584 - val_accuracy: 0.9755\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.1620 - val_accuracy: 0.9758\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.1631 - val_accuracy: 0.9754\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.1629 - val_accuracy: 0.9761\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.1581 - val_accuracy: 0.9760\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.1654 - val_accuracy: 0.9764\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 0.1599 - val_accuracy: 0.9759\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.1686 - val_accuracy: 0.9764\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.1632 - val_accuracy: 0.9767\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.1703 - val_accuracy: 0.9765\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.1636 - val_accuracy: 0.9759\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.1714 - val_accuracy: 0.9761\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.1736 - val_accuracy: 0.9765\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.1708 - val_accuracy: 0.9758\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.1742 - val_accuracy: 0.9757\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.1743 - val_accuracy: 0.9759\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.1791 - val_accuracy: 0.9764\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.1818 - val_accuracy: 0.9760\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.1760 - val_accuracy: 0.9761\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.1766 - val_accuracy: 0.9764\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.1815 - val_accuracy: 0.9763\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.1809 - val_accuracy: 0.9764\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.1761 - val_accuracy: 0.9763\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.1853 - val_accuracy: 0.9762\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.1846 - val_accuracy: 0.9766\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.1823 - val_accuracy: 0.9760\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.1883 - val_accuracy: 0.9761\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.1848 - val_accuracy: 0.9765\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.1889 - val_accuracy: 0.9766\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.1944 - val_accuracy: 0.9768\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1890 - val_accuracy: 0.9765\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.1934 - val_accuracy: 0.9767\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1844 - val_accuracy: 0.9760\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.1908 - val_accuracy: 0.9766\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.1865 - val_accuracy: 0.9759\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.1921 - val_accuracy: 0.9760\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.1936 - val_accuracy: 0.9762\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.1854 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28583cb80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, np.array(y_train), validation_data=(X_val, np.array(y_val)), batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 21ms/step - loss: 0.2908 - accuracy: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29075345396995544, 0.9731842279434204]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, np.array(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
